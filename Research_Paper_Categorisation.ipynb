{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b126a5053989431688ae177fce8500dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d42fc48c6d44c6d89bb688931dbb1ef",
              "IPY_MODEL_96215445b2864cc499be2d5f62bbaf78",
              "IPY_MODEL_5b3ca58efb444732905cb250f3335e92"
            ],
            "layout": "IPY_MODEL_df8f51c8fe184944a5a0df340c9fac02"
          }
        },
        "5d42fc48c6d44c6d89bb688931dbb1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94b2a36b43814bd2b51ccee5130aa859",
            "placeholder": "​",
            "style": "IPY_MODEL_f5c0fb6e83214debb43eed700edbef08",
            "value": "  0%"
          }
        },
        "96215445b2864cc499be2d5f62bbaf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b15fd17ce32d421c853ae3d863d45751",
            "max": 6082,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e62e2966da8442494ce5dcb267bed6f",
            "value": 1
          }
        },
        "5b3ca58efb444732905cb250f3335e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa119bb2195d40c9b4008e6a7230b027",
            "placeholder": "​",
            "style": "IPY_MODEL_6ed17e6e4343433c8cc7e6a1bf0e7d53",
            "value": " 1/6082 [01:16&lt;128:45:05, 76.22s/it]"
          }
        },
        "df8f51c8fe184944a5a0df340c9fac02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94b2a36b43814bd2b51ccee5130aa859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c0fb6e83214debb43eed700edbef08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b15fd17ce32d421c853ae3d863d45751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e62e2966da8442494ce5dcb267bed6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa119bb2195d40c9b4008e6a7230b027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed17e6e4343433c8cc7e6a1bf0e7d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_1GSusG0BnG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NAMELIST = ['math.AT', 'stat.AP', 'cs.AR', 'math.QA', 'q-bio.MN', 'eess.AS','eess.IV', 'stat.ME', 'econ.GN',\n",
        "            'eess.SP', 'q-fin.RM', 'cs.LG', 'cs.CR', 'q-bio.BM', 'q-fin.GN', 'q-fin.MF', 'q-fin.PR', 'math.CV',\n",
        "            'cs.LO', 'econ.TH', 'math.CO', 'cs.AI', 'math.AC', 'q-bio.CB','q-fin.CP', 'cs.CL', 'cs.DC', 'math.LO',\n",
        "            'math.NT', 'cs.SD', 'q-fin.TR','cs.CV', 'stat.ML', 'q-fin.EC', 'econ.EM', 'cs.CE', 'stat.CO','math.PR',\n",
        "            'q-bio.NC', 'math.AP', 'cs.OS', 'cs.NI', 'cs.IT', 'cs.PL', 'cs.GT', 'cs.DM', 'math.IT', 'cs.SE', 'cs.RO',\n",
        "            'stat.TH', 'cs.DB','math.ST', 'q-bio.GN', 'q-fin.PM', 'q-bio.TO', 'math.GR', 'cs.IR']\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "LEARNING_RATE = 1e-5\n",
        "EPOCHS = 6\n",
        "THRESHOLD = 0.1"
      ],
      "metadata": {
        "id": "YMTUTQTY00cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/train.csv\")"
      ],
      "metadata": {
        "id": "NnKn6Hsx03h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(frac = 1, random_state = 42)"
      ],
      "metadata": {
        "id": "f3_TAMJN065g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data[:48650]\n",
        "val_data = data[48650:] # 95-5 Split"
      ],
      "metadata": {
        "id": "KhuPWayq2if2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_from_string(text): #parses list-string to list of strings\n",
        "\n",
        "    text = text[1:-1]\n",
        "    text = text.replace(\" \", \"\")\n",
        "    text = text.replace(\"'\", \"\")\n",
        "    list = text.split(',')\n",
        "\n",
        "    return list"
      ],
      "metadata": {
        "id": "MgYRUp062lpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_one_hot_vec(text):\n",
        "\n",
        "    wlist = get_list_from_string(text)\n",
        "\n",
        "    vec = []\n",
        "\n",
        "    for name in NAMELIST:\n",
        "\n",
        "        vec.append(1 if name in wlist else 0)\n",
        "\n",
        "    return vec"
      ],
      "metadata": {
        "id": "w4KVs06p2n_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pylatexenc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKHoFnUH2qLn",
        "outputId": "51c7e85f-3e92-4abc-c087-ff4bb3c3ab1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pylatexenc in /usr/local/lib/python3.10/dist-packages (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pylatexenc.latex2text import LatexNodes2Text"
      ],
      "metadata": {
        "id": "2E-t_9XS2spV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_space(text):\n",
        "    text = text.strip()\n",
        "    text = text.split()\n",
        "    return \" \".join(text)\n",
        "\n",
        "def lowerall(text):\n",
        "\n",
        "    text = text.split()\n",
        "    lwords = [word.lower() for word in text]\n",
        "    return \" \".join(lwords)\n",
        "\n",
        "def remove_links(input_string):\n",
        "\n",
        "    pattern1 = r'\\\\href\\{.*?\\}\\{.*?\\}'\n",
        "    pattern2 = r'\\\\href\\{.*?\\}'\n",
        "    pattern3 = r'\\\\url\\{.*?\\}'\n",
        "\n",
        "    cleaned_string = re.sub(pattern1, '', input_string)\n",
        "    cleaned_string = re.sub(pattern2, '', cleaned_string)\n",
        "    cleaned_string = re.sub(pattern3, '', cleaned_string)\n",
        "\n",
        "    return cleaned_string\n",
        "\n",
        "def clean_text(text):\n",
        "    text = remove_space(text)\n",
        "    text = remove_links(text)\n",
        "\n",
        "    text = LatexNodes2Text().latex_to_text(text)\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s.,;:!?(){}\\[\\]<>+-/*=%$&@#~≥\\\\_~`]', '', text)\n",
        "\n",
        "    text = lowerall(text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "ON3mk3pA2v6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eY6MTQe3S1e",
        "outputId": "6c4e45fe-20f2-4fb7-fc3f-20dfbb60ea66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TheDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, test):\n",
        "\n",
        "        self.IDs = df['Id'].values\n",
        "        Abstracts = df['Abstract'].values\n",
        "        Titles = df['Title'].values\n",
        "\n",
        "        self.test = test\n",
        "\n",
        "        self.Texts = []\n",
        "\n",
        "        for i in range(len(self.IDs)):\n",
        "\n",
        "            self.Texts.append(clean_text(Titles[i] + ' ' + Abstracts[i]))\n",
        "\n",
        "\n",
        "        if not self.test:\n",
        "\n",
        "            Cats = df['Categories'].values\n",
        "            self.Vectors = [get_one_hot_vec(cat) for cat in Cats]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.IDs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        the_text = self.Texts[idx]\n",
        "\n",
        "        inputs = bert_tokenizer.encode_plus(\n",
        "            the_text,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length= 510,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        if self.test:\n",
        "            return {\n",
        "                'textID' : self.IDs[idx],\n",
        "                'ids': torch.tensor(ids, dtype=torch.long),\n",
        "                'mask': torch.tensor(mask, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'textID' : self.IDs[idx],\n",
        "                'ids': torch.tensor(ids, dtype=torch.long),\n",
        "                'mask': torch.tensor(mask, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "                'targets': torch.Tensor(self.Vectors[idx])\n",
        "            }"
      ],
      "metadata": {
        "id": "YO1TsWob3bqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "        self.fc1 = nn.Linear(768, 1024)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(1024, 57)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, features = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
        "        out1 = self.fc1(features)\n",
        "        out2 = self.relu(out1)\n",
        "        out = self.fc2(out2)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "vhxbNstu3fz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet()\n",
        "model.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO8RwlHh3ipQ",
        "outputId": "932e188f-0ebf-47bc-fab1-e16693177f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=1024, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=1024, out_features=57, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "metadata": {
        "id": "drjcANoC3olP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE, weight_decay = 1e-6)\n",
        "train_dataset = TheDataset(train_data, False)\n",
        "val_dataset = TheDataset(val_data, False)\n",
        "train_loader = DataLoader(train_dataset, batch_size = 8, num_workers = 4)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 8, num_workers = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl6qa9Ie3uau",
        "outputId": "b32786fe-b3f8-4898-c227-979bdf99a4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pylatexenc.latex2text:WARNING: Error in configuration: macro '\\frac' failed its substitution!\n",
            "WARNING:pylatexenc.latex2text:WARNING: Error in configuration: macro '\\frac' failed its substitution!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer):\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    progress = tqdm(train_loader, total=len(train_loader))\n",
        "\n",
        "    for _, data in enumerate(progress):\n",
        "\n",
        "        ids = data['ids'].to(DEVICE, dtype = torch.long)\n",
        "        mask = data['mask'].to(DEVICE, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(DEVICE, dtype = torch.long)\n",
        "\n",
        "        targets = data['targets'].to(DEVICE, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    return np.mean(losses)"
      ],
      "metadata": {
        "id": "e0EWd0_33yiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(val_loader, model):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "\n",
        "    progress = tqdm(val_loader, total=len(val_loader))\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, data in enumerate(progress):\n",
        "\n",
        "            ids = data['ids'].to(DEVICE, dtype = torch.long)\n",
        "            mask = data['mask'].to(DEVICE, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(DEVICE, dtype = torch.long)\n",
        "\n",
        "            targets = data['targets'].to(DEVICE, dtype = torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "\n",
        "            outlist = torch.sigmoid(outputs).cpu().detach().numpy().tolist()\n",
        "\n",
        "            one_hot_out = []\n",
        "\n",
        "            for outl in outlist:\n",
        "\n",
        "                yo = []\n",
        "\n",
        "                for term in outl:\n",
        "\n",
        "                    if(term >= THRESHOLD):\n",
        "\n",
        "                        yo.append(1)\n",
        "\n",
        "                    else:\n",
        "\n",
        "                        yo.append(0)\n",
        "\n",
        "                one_hot_out.append(yo)\n",
        "\n",
        "\n",
        "            fin_outputs.extend(one_hot_out)\n",
        "\n",
        "    return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "ESOcUv9C33dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "jydYcFto39M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "\n",
        "best_dict = None\n",
        "best_loss = np.inf\n",
        "\n",
        "for ep in range(EPOCHS):\n",
        "\n",
        "    print('='*5 + f\" Epoch {ep+1} \" + '='*5)\n",
        "\n",
        "    tr_loss = train_fn(train_loader, model, loss_fn, optimizer)\n",
        "\n",
        "    if tr_loss < best_loss:\n",
        "        best_loss = tr_loss\n",
        "        best_dict = model.state_dict()\n",
        "\n",
        "        checkpoint = {'model': model, 'state_dict': model.state_dict()}\n",
        "        torch.save(checkpoint, 'checkpoint.pth')\n",
        "\n",
        "    train_losses.append(tr_loss)\n",
        "\n",
        "    print(f\"Epoch {ep + 1} - Train Loss {tr_loss:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b126a5053989431688ae177fce8500dd",
            "5d42fc48c6d44c6d89bb688931dbb1ef",
            "96215445b2864cc499be2d5f62bbaf78",
            "5b3ca58efb444732905cb250f3335e92",
            "df8f51c8fe184944a5a0df340c9fac02",
            "94b2a36b43814bd2b51ccee5130aa859",
            "f5c0fb6e83214debb43eed700edbef08",
            "b15fd17ce32d421c853ae3d863d45751",
            "8e62e2966da8442494ce5dcb267bed6f",
            "fa119bb2195d40c9b4008e6a7230b027",
            "6ed17e6e4343433c8cc7e6a1bf0e7d53"
          ]
        },
        "id": "Rz9_ycf54GGl",
        "outputId": "d85a9701-a224-43c6-8b45-a7f3f97d2705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Epoch 1 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b126a5053989431688ae177fce8500dd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics"
      ],
      "metadata": {
        "id": "2I2pwV3W4Ijg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, targets = validation(val_loader, model)\n",
        "\n",
        "f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "id": "JGdLp81F4NaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preds(test_loader, model):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "\n",
        "    progress = tqdm(test_loader, total=len(test_loader))\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        pred_dict = {}\n",
        "\n",
        "        for _, data in enumerate(progress):\n",
        "\n",
        "            textid = data['textID']\n",
        "\n",
        "            ids = data['ids'].to(DEVICE, dtype = torch.long)\n",
        "            mask = data['mask'].to(DEVICE, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(DEVICE, dtype = torch.long)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            outlist = torch.sigmoid(outputs).cpu().detach().numpy().tolist()\n",
        "\n",
        "            one_hot_out = []\n",
        "\n",
        "            for outl in outlist:\n",
        "\n",
        "                yo = []\n",
        "\n",
        "                for term in outl:\n",
        "\n",
        "                    if(term >= THRESHOLD):\n",
        "\n",
        "                        yo.append(1)\n",
        "\n",
        "                    else:\n",
        "\n",
        "                        yo.append(0)\n",
        "\n",
        "                one_hot_out.append(yo)\n",
        "\n",
        "            pred_dict[textid] = one_hot_out\n",
        "\n",
        "\n",
        "    return pred_dict"
      ],
      "metadata": {
        "id": "OhW6obr-4Tbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdf = pd.read_csv(\"/content/test.csv\")"
      ],
      "metadata": {
        "id": "01OwpJzl4XZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TheDataset(testdf, test = True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size = 8, num_workers = 4)\n",
        "pred_dict = get_preds(test_loader, model)\n",
        "pred_df = pd.DataFrame(list(pred_dict.items()), columns=['Id', 'OneHotVec'])"
      ],
      "metadata": {
        "id": "sNuH2xbA4dQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred_dict = {}\n",
        "for i in range(1372):\n",
        "\n",
        "    for _, id in enumerate(pred_df['Id'][i]):\n",
        "\n",
        "        id = id.numpy()\n",
        "        id = id.item()\n",
        "\n",
        "        final_pred_dict[id] = pred_df['OneHotVec'][i][_]\n",
        "final_pred_df = pd.DataFrame(list(final_pred_dict.items()), columns=['Id', 'OneHotVec'])\n",
        "for i, name in enumerate(NAMELIST):\n",
        "  final_pred_df[name] = final_pred_df['OneHotVec'].apply(lambda x : x[i])\n",
        "\n",
        "final_pred_df = final_pred_df.drop(['OneHotVec'], axis = 1)\n",
        "final_pred_df\n",
        "final_pred_df.to_csv('Output.csv', index = False)"
      ],
      "metadata": {
        "id": "xlpCvCoG-QZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}